{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransferLearning_TrickY_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1iK6zf5Gyn50s9FPRzzFy2qx5YpVDJcXc",
      "authorship_tag": "ABX9TyNxyKSMbneZe7c0o0rS0AwX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VijayRameshkumar/Deep_Learning/blob/gh-pages/MachineLearning/19_TrickyCNN_TransferLearning/TransferLearning_TrickY_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuW9JcezWk7x"
      },
      "source": [
        "!mkdir /content/dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_hh2h8Jb0-P",
        "outputId": "da5ba6ed-7b29-4ed7-f50f-851501ca1768"
      },
      "source": [
        "%cd /content/dataset/\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6UNejC1PgUI"
      },
      "source": [
        "!mkdir data\n",
        "!unrar x -r '/content/drive/MyDrive/19_Trasfer Learning/rvl-cdip.rar' ./data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TN65V0BqWj6k",
        "outputId": "56e35085-c318-4c1a-9f1d-d6f00dd44036"
      },
      "source": [
        "%cd data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/dataset/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRaUZhwDWv2W",
        "outputId": "650c9e75-dc59-4e68-97ae-8a963dc013f2"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata_final\u001b[0m/  labels_final.csv  \u001b[01;34mlogs\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-bObAstWxJm"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import keras\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D\n",
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, BatchNormalization\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, TensorBoard, LambdaCallback\n",
        "\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPTO4AjvCnvd"
      },
      "source": [
        "[Data Augmentation using IMGAUG and Preprocessing Pipeline](https://www.kaggle.com/mpalermo/keras-pipeline-custom-generator-imgaug)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDa9ImBliBCo"
      },
      "source": [
        "# 1. Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Oof54QP_XhF-",
        "outputId": "62dfaca5-4f0c-4d65-8a1d-8b24e8405dda"
      },
      "source": [
        "df = pd.read_csv('/content/dataset/data/labels_final.csv')\n",
        "# df['label'] = df['label'].astype('str')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>imagesv/v/o/h/voh71d00/509132755+-2755.tif</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>imagesl/l/x/t/lxt19d00/502213303.tif</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>imagesx/x/e/d/xed05a00/2075325674.tif</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>imageso/o/j/b/ojb60d00/517511301+-1301.tif</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>imagesq/q/z/k/qzk17e00/2031320195.tif</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         path  label\n",
              "0  imagesv/v/o/h/voh71d00/509132755+-2755.tif      3\n",
              "1        imagesl/l/x/t/lxt19d00/502213303.tif      3\n",
              "2       imagesx/x/e/d/xed05a00/2075325674.tif      2\n",
              "3  imageso/o/j/b/ojb60d00/517511301+-1301.tif      3\n",
              "4       imagesq/q/z/k/qzk17e00/2031320195.tif      7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwUjUu3XXwhp"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "root = \"data_final/\"\n",
        "\n",
        "# width = []\n",
        "# height = []\n",
        "\n",
        "# for im_path in df.path:\n",
        "#   im_path = root + im_path\n",
        "#   img = cv2.imread(im_path)\n",
        "#   height.append(img.shape[0])\n",
        "#   width.append(img.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6qa2GEofhj-"
      },
      "source": [
        "##plotting \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.hist(width,bins=20)\n",
        "plt.xlim(0,1000)\n",
        "plt.title('width')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKPij25mZ9zO",
        "outputId": "1dac6ca4-bf51-4e4f-c31e-684237d23401"
      },
      "source": [
        "# mean_width = sum(width) // len(width)\n",
        "# mean_height = sum(height) // len(height)\n",
        "\n",
        "# print(f\"Total {len(width)} of images\")\n",
        "# print(f\"min {min(width)}, max {max(width)}, mean_width {mean_width}\")\n",
        "# print(f\"min {min(height)}, max {max(height)}, mean_height {mean_height}\")\n",
        "\n",
        "batch_size = 64\n",
        "step = 48000 / batch_size\n",
        "print(f\"batch_size is {batch_size}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch_size is 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht0e6j5b--qZ",
        "outputId": "81f0ed19-d1f7-49dc-bcb3-d2acac38dbb5"
      },
      "source": [
        "print(f\"labels with counts :\\n\")\n",
        "\n",
        "print(df.label.value_counts().sort_index(ascending = True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels with counts :\n",
            "\n",
            "0     3016\n",
            "1     2994\n",
            "2     2993\n",
            "3     3005\n",
            "4     2994\n",
            "5     2999\n",
            "6     2985\n",
            "7     3000\n",
            "8     3003\n",
            "9     3002\n",
            "10    3002\n",
            "11    2992\n",
            "12    3006\n",
            "13    3007\n",
            "14    3006\n",
            "15    2996\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdhsK-WH-yOa"
      },
      "source": [
        "#2. Data-Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqJvkyuwZuGK",
        "outputId": "ef6d3330-5a54-44de-cecc-1d286c1506fc"
      },
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(df['path'], df['label'], test_size=0.2, stratify=df['label'])\n",
        "\n",
        "print(xtrain.shape, xtest.shape, ytrain.shape, ytest.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(38400,) (9600,) (38400,) (9600,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeeaMp7eiE16"
      },
      "source": [
        "# 2 . Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "sYyPcYJIHDcl",
        "outputId": "36dc3296-4fcf-498d-fe3f-51123f0212c2"
      },
      "source": [
        "import gc\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, images_paths, labels, batch_size=batch_size, \n",
        "              image_dimensions = (1000 ,700 ,3), shuffle=False, augment=False):\n",
        "     \n",
        "        self.labels       = labels              # array of labels\n",
        "        self.images_paths = images_paths        # array of image paths\n",
        "        self.dim          = image_dimensions    # image dimensions\n",
        "        self.batch_size   = batch_size          # batch size\n",
        "        self.shuffle      = shuffle             # shuffle bool\n",
        "        self.augment      = augment             # augment data bool\n",
        "        self.on_epoch_end()\n",
        "        gc.collect()\n",
        "  \n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.images_paths) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.images_paths))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # selects indices of data for next batch\n",
        "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "        root = 'data_final/'\n",
        "\n",
        "        # select data and load images\n",
        "        labels = np.array([self.labels[k] for k in indexes])\n",
        "\n",
        "        images = []\n",
        "        for k in indexes:\n",
        "            img = cv2.imread(root + self.images_paths[k])\n",
        "            img = cv2.resize(img, (1000, 700))\n",
        "            images.append(img)\n",
        "        \n",
        "        # preprocess and augment data\n",
        "        if self.augment == True:\n",
        "            images = self.augmentor(images)\n",
        "\n",
        "        return np.asarray(images), labels\n",
        "    \n",
        "    \n",
        "    def augmentor(self, images):\n",
        "        'Apply data augmentation'\n",
        "        sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "        seq = iaa.Sequential(\n",
        "                [\n",
        "                # apply the following augmenters to most images\n",
        "                iaa.Fliplr(0.5),  # horizontally flip 50% of all images\n",
        "                iaa.Flipud(0.2),  # vertically flip 20% of all images\n",
        "                sometimes(iaa.Affine(\n",
        "                    # scale images to 80-120% of their size, individually per axis\n",
        "                    translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
        "                    # translate by -20 to +20 percent (per axis)\n",
        "                    rotate=(-10, 10),  # rotate by -45 to +45 degrees\n",
        "                    shear=(-5, 5),  # shear by -16 to +16 degrees\n",
        "                    order=[0, 1],\n",
        "                    # use nearest neighbour or bilinear interpolation (fast)\n",
        "                    cval=(0, 255),  # if mode is constant, use a cval between 0 and 255\n",
        "                    mode=ia.ALL\n",
        "                    # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
        "                )),\n",
        "                # execute 0 to 5 of the following (less important) augmenters per image\n",
        "                # don't execute all of them, as that would often be way too strong\n",
        "                iaa.SomeOf((0, 5),\n",
        "                           [sometimes(iaa.Superpixels(p_replace=(0, 1.0),\n",
        "                                                             n_segments=(20, 200))),\n",
        "                               # convert images into their superpixel representation\n",
        "                               iaa.OneOf([\n",
        "                                       iaa.GaussianBlur((0, 1.0)),\n",
        "                                       # blur images with a sigma between 0 and 3.0\n",
        "                                       iaa.AverageBlur(k=(3, 5)),\n",
        "                                       # blur image using local means with kernel sizes between 2 and 7\n",
        "                                       iaa.MedianBlur(k=(3, 5)),\n",
        "                                       # blur image using local medians with kernel sizes between 2 and 7\n",
        "                               ]),\n",
        "                               iaa.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)),\n",
        "                               # sharpen images\n",
        "                               iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)),\n",
        "                               # emboss images\n",
        "                               # search either for all edges or for directed edges,\n",
        "                               # blend the result with the original image using a blobby mask\n",
        "                               iaa.SimplexNoiseAlpha(iaa.OneOf([\n",
        "                                       iaa.EdgeDetect(alpha=(0.5, 1.0)),\n",
        "                                       iaa.DirectedEdgeDetect(alpha=(0.5, 1.0),\n",
        "                                                              direction=(0.0, 1.0)),\n",
        "                               ])),\n",
        "                               iaa.AdditiveGaussianNoise(loc=0,\n",
        "                                                         scale=(0.0, 0.01 * 255),\n",
        "                                                         per_channel=0.5),\n",
        "                               # add gaussian noise to images\n",
        "                               iaa.OneOf([\n",
        "                                       iaa.Dropout((0.01, 0.05), per_channel=0.5),\n",
        "                                       # randomly remove up to 10% of the pixels\n",
        "                                       iaa.CoarseDropout((0.01, 0.03),\n",
        "                                                         size_percent=(0.01, 0.02),\n",
        "                                                         per_channel=0.2),\n",
        "                               ]),\n",
        "                               iaa.Invert(0.01, per_channel=True),\n",
        "                               # invert color channels\n",
        "                               iaa.Add((-2, 2), per_channel=0.5),\n",
        "                               # change brightness of images (by -10 to 10 of original value)\n",
        "                               iaa.AddToHueAndSaturation((-1, 1)),\n",
        "                               # change hue and saturation\n",
        "                               # either change the brightness of the whole image (sometimes\n",
        "                               # per channel) or change the brightness of subareas\n",
        "                               iaa.OneOf([\n",
        "                                       iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
        "                                       iaa.FrequencyNoiseAlpha(\n",
        "                                               exponent=(-1, 0),\n",
        "                                               first=iaa.Multiply((0.9, 1.1),\n",
        "                                                                  per_channel=True),\n",
        "                                               second=iaa.ContrastNormalization(\n",
        "                                                       (0.9, 1.1))\n",
        "                                       )\n",
        "                               ]),\n",
        "                               sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5),\n",
        "                                                                   sigma=0.25)),\n",
        "                               # move pixels locally around (with random strengths)\n",
        "                               sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))),\n",
        "                               # sometimes move parts of the image around\n",
        "                               sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
        "                           ],\n",
        "                           random_order=True\n",
        "                           )\n",
        "                ],\n",
        "                random_order=True\n",
        "        )\n",
        "        return seq.augment_images(images)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-11a52e5be975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m'Generates data for Keras'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     def __init__(self, images_paths, labels, batch_size=batch_size, \n",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3UiUNJRHpCd"
      },
      "source": [
        "# Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZizkOv3-Hses"
      },
      "source": [
        "class VGG16_TL():\n",
        "    def __init__(self, image_dimensions=(1000,700 ,3), n_classes=16):\n",
        "        self.n_classes = n_classes  # number of classes to classify(1 for binary classification)\n",
        "        self.input_dim = image_dimensions  # image input dimensions\n",
        "        self.model = self.create_model()  # model\n",
        "\n",
        "    def summary(self):\n",
        "        self.model.summary()\n",
        "  \n",
        "    def create_model(self,):\n",
        "        # Loading Model\n",
        "        pretrained_model = VGG16(input_shape=(1000, 700, 3), include_top=False, weights=\"imagenet\")\n",
        "        \n",
        "        # Freezing the layers\n",
        "        for layer in pretrained_model.layers[:15]:\n",
        "            layer.trainable = False\n",
        "        for layer in pretrained_model.layers[15:]:\n",
        "            layer.trainable = True\n",
        "\n",
        "        # Modification of pretrained model\n",
        "        last_layer = pretrained_model.get_layer('block5_pool')\n",
        "        last_output = last_layer.output\n",
        "\n",
        "        x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block6_conv1')(last_output)\n",
        "        x = GlobalMaxPooling2D()(x)\n",
        "        x = Dense(512, activation='relu', name='fc1')(x)\n",
        "        x = Dropout(0.4)(x)\n",
        "        x = Dense(216, activation='relu', name='fc2')(x)\n",
        "        x = Dense(self.n_classes, activation='softmax', name='predictions')(x)\n",
        "\n",
        "        # Creating a new model\n",
        "        model = Model(pretrained_model.input, x)\n",
        "\n",
        "        model.compile(loss='binary_crossentropy',\n",
        "                optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def train(self, train_data, val_data, plot_results=True):\n",
        "        'Trains data on generators'\n",
        "        print(\"Starting training\")\n",
        "\n",
        "        # reduces learning rate if no improvement are seen\n",
        "        learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss',\n",
        "                                                    patience=2,\n",
        "                                                    verbose=1,\n",
        "                                                    factor=0.5,\n",
        "                                                    min_lr=0.0000001)\n",
        "\n",
        "        # stop training if no improvements are seen\n",
        "        early_stop = EarlyStopping(monitor=\"val_loss\",\n",
        "                                   mode=\"min\",\n",
        "                                   patience=5,\n",
        "                                   restore_best_weights=True)\n",
        "\n",
        "        # saves model weights to file\n",
        "        checkpoint = ModelCheckpoint('./model_weights.hdf5',\n",
        "                                     monitor='val_loss',\n",
        "                                     verbose=1,\n",
        "                                     save_best_only=True,\n",
        "                                     mode='min',\n",
        "                                     save_weights_only=True)\n",
        "\n",
        "        # visualize training data\n",
        "        tensorboard = TensorBoard(log_dir='./logs',\n",
        "                                 histogram_freq=0,\n",
        "                                 batch_size=128,\n",
        "                                 write_graph=True,\n",
        "                                 write_grads=True,\n",
        "                                 write_images=False)\n",
        "\n",
        "        # reduce resource usage(keeps laptop from melting)\n",
        "        # idle = LambdaCallback(on_epoch_end=lambda batch, logs: time.sleep(30),\n",
        "        #                      on_batch_end=lambda batch, logs: time.sleep(0.005))\n",
        "\n",
        "        # train on data\n",
        "        history = self.model.fit_generator(generator=train_data,\n",
        "                                           validation_data=val_data,\n",
        "                                           epochs=EPOCHS,\n",
        "                                           steps_per_epoch=600,\n",
        "                                           validation_steps =150,\n",
        "                                           callbacks=[learning_rate_reduction, early_stop, checkpoint, tensorboard],\n",
        "                                           verbose=2,\n",
        "                                           )\n",
        "        # plot training history\n",
        "        if plot_results:\n",
        "            fig, ax = plt.subplots(2, 1, figsize=(6, 6))\n",
        "            ax[0].plot(history.history['loss'], label=\"TrainLoss\")\n",
        "            ax[0].plot(history.history['val_loss'], label=\"ValLoss\")\n",
        "            ax[0].legend(loc='best', shadow=True)\n",
        "\n",
        "            ax[1].plot(history.history['acc'], label=\"TrainAcc\")\n",
        "            ax[1].plot(history.history['val_acc'], label=\"ValAcc\")\n",
        "            ax[1].legend(loc='best', shadow=True)\n",
        "            plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEZwGRvvboBR"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "xtrain = xtrain.reset_index(drop=True).values\n",
        "xtest = xtest.reset_index(drop=True).values\n",
        "\n",
        "ytrain = ytrain.reset_index(drop=True).values\n",
        "ytest = ytest.reset_index(drop=True).values\n",
        "\n",
        "\n",
        "# One-hot encode data\n",
        "ytrain = np_utils.to_categorical(ytrain)\n",
        "ytest = np_utils.to_categorical(ytest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jT400mtS4cQ",
        "outputId": "15ff9a7d-be40-40c9-d192-a659ee5b9a54"
      },
      "source": [
        "def loadData(db, val_split=0.2, sub_sample_size=-1):\n",
        "    'Loads data into generator object'\n",
        "    if db == \"train\":\n",
        "        train_data = DataGenerator(xtrain, ytrain, batch_size=batch_size, augment=True, shuffle=True)\n",
        "        val_data = DataGenerator(xtest, ytest, batch_size=batch_size, augment=False, shuffle=False)\n",
        "        return train_data, val_data\n",
        "\n",
        "    else:\n",
        "        return DataGenerator(image_paths, labels, batch_size=BATCH_SIZE, augment=True, shuffle=True), None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    EPOCHS = 10\n",
        "    BATCH_SIZE = 64\n",
        "    IMAGE_DIMENSIONS = (1000,700 ,3)\n",
        "\n",
        "    # create model\n",
        "    model = VGG16_TL(image_dimensions=IMAGE_DIMENSIONS, n_classes=16)\n",
        "    model.summary()\n",
        "\n",
        "    # train model\n",
        "    train_data, val_data = loadData(\"train\", val_split=0.2)\n",
        "    model.train(train_data, val_data, plot_results=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1000, 700, 3)]    0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 1000, 700, 64)     1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 1000, 700, 64)     36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 500, 350, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 500, 350, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 500, 350, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 250, 175, 128)     0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 250, 175, 256)     295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 250, 175, 256)     590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 250, 175, 256)     590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 125, 87, 256)      0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 125, 87, 512)      1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 125, 87, 512)      2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 125, 87, 512)      2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 62, 43, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 62, 43, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 62, 43, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 62, 43, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 31, 21, 512)       0         \n",
            "_________________________________________________________________\n",
            "block6_conv1 (Conv2D)        (None, 31, 21, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d (Global (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 216)               110808    \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 16)                3472      \n",
            "=================================================================\n",
            "Total params: 17,451,432\n",
            "Trainable params: 9,816,168\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n",
            "Starting training\n",
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
            "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsfkEHE_bKsG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}